{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to your notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to connect to your GIS and get started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now you are ready to start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Install the correct libraries via pip or conda then run this part of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name: PRISMA2GeoTIFF.py\n",
    "#Description: reads he5 PRISMA files content and converts it to a GeoTIFF.\n",
    "#All 66 VNIR bands and 173 SWIR bands are converted in one single GeoTIFF file.\n",
    "#input is a PRISMA he5 file and output is a GeoTIFF with the same name in the same path\n",
    "#Author: martin rapilly, mrapilly60@uasd.edu.do/martin.rapilly@get.omp.eu\n",
    "\n",
    "#import libraries\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from osgeo import gdal, osr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run this code to initiate the function PRISMA2GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PRISMA2GeoTIFF(filename):\n",
    "\n",
    "    def first_existing(h5f, paths):\n",
    "        for p in paths:\n",
    "            if p in h5f:\n",
    "                return p\n",
    "        return None\n",
    "\n",
    "    with h5py.File(filename, \"r\") as h5f:\n",
    "\n",
    "        # --- detect which PRISMA swath exists (prefer L2D if present) ---\n",
    "        swath = first_existing(h5f, [\n",
    "            \"HDFEOS/SWATHS/PRS_L2D_HCO\",\n",
    "            \"HDFEOS/SWATHS/PRS_L2D_HRC\",\n",
    "            \"HDFEOS/SWATHS/PRS_L1_HCO\",\n",
    "            \"HDFEOS/SWATHS/PRS_L1_HRC\",\n",
    "        ])\n",
    "        if swath is None:\n",
    "            raise KeyError(\"No PRISMA swath found under HDFEOS/SWATHS (expected PRS_L1_* or PRS_L2D_*).\")\n",
    "\n",
    "        # groups\n",
    "        data_fields = first_existing(h5f, [f\"{swath}/Data Fields\", f\"{swath}/Data_Fields\"])\n",
    "        geo_fields  = first_existing(h5f, [f\"{swath}/Geolocation Fields\", f\"{swath}/Geolocation_Fields\"])\n",
    "        if data_fields is None:\n",
    "            raise KeyError(f\"Found swath {swath} but no Data Fields group.\")\n",
    "        if geo_fields is None:\n",
    "            raise KeyError(f\"Found swath {swath} but no Geolocation Fields group.\")\n",
    "\n",
    "        # cubes\n",
    "        swir_path = first_existing(h5f, [f\"{data_fields}/SWIR_Cube\"])\n",
    "        vnir_path = first_existing(h5f, [f\"{data_fields}/VNIR_Cube\"])\n",
    "        if swir_path is None or vnir_path is None:\n",
    "            raise KeyError(f\"Missing VNIR/SWIR cubes. Available: {list(h5f[data_fields].keys())}\")\n",
    "\n",
    "        # --- geolocation: L2D uses Latitude/Longitude; L1 may use *_VNIR / *_SWIR ---\n",
    "        lat_path = first_existing(h5f, [\n",
    "            f\"{geo_fields}/Latitude\",\n",
    "            f\"{geo_fields}/Latitude_VNIR\",\n",
    "            f\"{geo_fields}/Latitude_SWIR\",\n",
    "        ])\n",
    "        lon_path = first_existing(h5f, [\n",
    "            f\"{geo_fields}/Longitude\",\n",
    "            f\"{geo_fields}/Longitude_VNIR\",\n",
    "            f\"{geo_fields}/Longitude_SWIR\",\n",
    "        ])\n",
    "        if lat_path is None or lon_path is None:\n",
    "            raise KeyError(\n",
    "                f\"No usable Latitude/Longitude found. Available: {list(h5f[geo_fields].keys())}\"\n",
    "            )\n",
    "\n",
    "        # read arrays\n",
    "        SWIRcube = h5f[swir_path][()]   # expected shape often (rows, bands, cols) but may vary\n",
    "        VNIRcube = h5f[vnir_path][()]\n",
    "        lat = h5f[lat_path][()]\n",
    "        lon = h5f[lon_path][()]\n",
    "\n",
    "        print(\"Using swath:\", swath)\n",
    "        print(\"SWIR path:\", swir_path, \"shape:\", SWIRcube.shape)\n",
    "        print(\"VNIR path:\", vnir_path, \"shape:\", VNIRcube.shape)\n",
    "        print(\"LAT/LON paths:\", lat_path, lon_path, \"shapes:\", lat.shape, lon.shape)\n",
    "\n",
    "        # --- normalize cube layout to (bands, rows, cols) ---\n",
    "        # Your original code assumes cube indexed like VNIRcube[row][band] returning a row vector (cols).\n",
    "        # That corresponds to VNIRcube shape (rows, bands, cols).\n",
    "        # We'll handle both common cases: (rows, bands, cols) or (bands, rows, cols)\n",
    "        def to_brc(cube):\n",
    "            if cube.ndim != 3:\n",
    "                raise ValueError(f\"Expected 3D cube, got shape {cube.shape}\")\n",
    "            # if first dim equals lat rows and second dim looks like bands => (rows, bands, cols)\n",
    "            if cube.shape[0] == lat.shape[0] and cube.shape[2] == lat.shape[1]:\n",
    "                return np.transpose(cube, (1, 0, 2))  # -> (bands, rows, cols)\n",
    "            # if already (bands, rows, cols)\n",
    "            if cube.shape[1] == lat.shape[0] and cube.shape[2] == lat.shape[1]:\n",
    "                return cube\n",
    "            # fallback: try detect bands dimension as the one not matching lat rows/cols\n",
    "            raise ValueError(f\"Cube shape {cube.shape} doesn't match lat grid {lat.shape}\")\n",
    "\n",
    "        VNIR_brc = to_brc(VNIRcube)\n",
    "        SWIR_brc = to_brc(SWIRcube)\n",
    "\n",
    "        dataReshaped = np.concatenate([VNIR_brc, SWIR_brc], axis=0).astype(np.float32)\n",
    "        bands, rows, cols = dataReshaped.shape\n",
    "        print(\"Stacked shape (bands, rows, cols):\", dataReshaped.shape)\n",
    "\n",
    "        # --- crude affine geotransform from lat/lon (OK for quick-look; not perfect for L1) ---\n",
    "        xmin, xmax = float(lon.min()), float(lon.max())\n",
    "        ymin, ymax = float(lat.min()), float(lat.max())\n",
    "        xres = (xmax - xmin) / cols\n",
    "        yres = (ymax - ymin) / rows\n",
    "        geotransform = (xmin, xres, 0, ymax, 0, -yres)\n",
    "\n",
    "        # output\n",
    "        out_name = filename[:-4] + \"_stack.tif\"  # safer than [:-3]\n",
    "        driver = gdal.GetDriverByName(\"GTiff\")\n",
    "        output_raster = driver.Create(out_name, cols, rows, bands, gdal.GDT_Float32)\n",
    "\n",
    "        # write bands (GDAL bands are 1-based)\n",
    "        for b in range(bands):\n",
    "            outband = output_raster.GetRasterBand(b + 1)\n",
    "            outband.WriteArray(dataReshaped[b, :, :])\n",
    "\n",
    "        # tag CRS as WGS84 (since geotransform is in degrees)\n",
    "        output_raster.SetGeoTransform(geotransform)\n",
    "        srs = osr.SpatialReference()\n",
    "        srs.ImportFromEPSG(4326)\n",
    "        output_raster.SetProjection(srs.ExportToWkt())\n",
    "\n",
    "        output_raster.FlushCache()\n",
    "        output_raster = None\n",
    "\n",
    "        print(\"Wrote:\", out_name)\n",
    "        print(\"Conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Put one or many files in a folder. Modify the folder path and run this part of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he5 image list:  ['C:\\\\Users\\\\smclaugh1\\\\OneDrive - Freeport-McMoRan Inc\\\\projects_2026\\\\PRISMA\\\\PRS_L2D_STD_20241213102717_20241213102721_0001\\\\PRS_L2D_STD_20241213102717_20241213102721_0001.he5']\n",
      "Processing image C:\\Users\\smclaugh1\\OneDrive - Freeport-McMoRan Inc\\projects_2026\\PRISMA\\PRS_L2D_STD_20241213102717_20241213102721_0001\\PRS_L2D_STD_20241213102717_20241213102721_0001.he5\n",
      "Using swath: HDFEOS/SWATHS/PRS_L2D_HCO\n",
      "SWIR path: HDFEOS/SWATHS/PRS_L2D_HCO/Data Fields/SWIR_Cube shape: (1230, 57, 1313)\n",
      "VNIR path: HDFEOS/SWATHS/PRS_L2D_HCO/Data Fields/VNIR_Cube shape: (1230, 22, 1313)\n",
      "LAT/LON paths: HDFEOS/SWATHS/PRS_L2D_HCO/Geolocation Fields/Latitude HDFEOS/SWATHS/PRS_L2D_HCO/Geolocation Fields/Longitude shapes: (1230, 1313) (1230, 1313)\n",
      "Stacked shape (bands, rows, cols): (79, 1230, 1313)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smclaugh1\\AppData\\Local\\anaconda3\\Lib\\site-packages\\osgeo\\gdal.py:330: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\Users\\smclaugh1\\OneDrive - Freeport-McMoRan Inc\\projects_2026\\PRISMA\\PRS_L2D_STD_20241213102717_20241213102721_0001\\PRS_L2D_STD_20241213102717_20241213102721_0001_stack.tif\n",
      "Conversion complete.\n",
      "All files processed.\n"
     ]
    }
   ],
   "source": [
    "#enter folder path with he5 PRISMA files in it\n",
    "folderPath= r\"C:\\Users\\smclaugh1\\OneDrive - Freeport-McMoRan Inc\\projects_2026\\PRISMA\\PRS_L2D_STD_20241213102717_20241213102721_0001\"\n",
    "listImages=[]\n",
    "for file in os.listdir(folderPath):\n",
    "      listImages.append(os.path.join(folderPath, file))\n",
    "print (\"he5 image list: \", listImages)\n",
    "\n",
    "#apply function PRISMA2GeoTIFF\n",
    "for filename in listImages:\n",
    "    print(\"Processing image\", filename)\n",
    "    PRISMA2GeoTIFF(filename)\n",
    "print (\"All files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
